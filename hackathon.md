âš™ï¸ Concept: Self-Improving App via A/B Testing Agents

An AI system that continuously runs experiments on a live app â€” generating new features or variations, deploying them in isolated Daytona sandboxes, spawning browser agents to simulate user sessions, collecting results (conversion / dwell time / error rates), and then automatically merging the winning variant.

ğŸ¯ Demo Scenario

App: simple landing page with a â€œSign Upâ€ CTA.
Goal: â€œMaximize user conversion.â€

The systemâ€™s job:

Generate multiple variations of the landing page (copy, color, layout).

Run real browser simulations of â€œusersâ€ (agents) interacting.

Measure engagement metrics (clicks, scroll depth, time on page).

Auto-select the winner and merge it to main.

ğŸ§© Architecture Overview
Repo â†’ Daytona Sandbox Manager
â”‚
â””â”€â”€â–º Variant Generator (Claude Code)
     â”‚  creates N branches = feature variants
     â–¼
 Browser Use Agents swarm
     â”‚  simulate user sessions, record metrics
     â–¼
 Evaluator
     â”‚  aggregates metrics + feedback
     â–¼
 Auto-Merge â†’ best performing branch

ğŸ§  Step-by-Step Demo Flow
Step 1. Start Experiment

Command:

self_improving_app \
  --repo github.com/kubarogut/landing-page \
  --goal "Increase signup conversion"


System output:

ğŸ§ª Starting experiment: increase signup conversion
ğŸ“¦ Forked repo into 3 Daytona sandboxes
ğŸ¤– Generating variant ideas...


Claude Code (variant generator) produces:

Variant A: Change button color + copy

Variant B: Add testimonial section

Variant C: Simplify hero layout

Each variant = new branch, deployed sandbox.

Step 2. Spawn Browser Agents

10+ Browser Use agents run session replays for each variant.

They simulate user behavior (scroll, hover, click).

They collect telemetry:

Click rate on CTA

Time before bounce

Number of interactions

Step 3. Evaluation + Iteration

The Evaluator summarizes:

Variant A: 62% clicked CTA
Variant B: 78% clicked CTA
Variant C: 40% clicked CTA


Claude Reasoner reads results:

â€œVariant B improved conversion by 25%.
Letâ€™s refine testimonials text for next iteration.â€

It edits Variant Bâ€™s branch to create B2, runs the next loop.

Step 4. Auto-Merge Winning Variant

After N iterations:

ğŸ† Winner: Variant B2 (conversion +37%)
ğŸ”€ Merging to main branch...


Daytona rebuilds final sandbox â†’ live link.

ğŸ’» What You Actually Demo Live

Repo: minimal landing page app (index.html or Next.js page).

Goal input: â€œOptimize user conversion.â€

Visible console UI:

â€œGenerating 3 variantsâ€¦â€

â€œRunning browser agentsâ€¦â€

â€œEvaluating metricsâ€¦â€

Progress bars or live metric display.

Split-screen visualization (optional):

Left: three sandbox previews (A/B/C)

Right: logs of simulated users + metrics updating

Final moment:

Graph showing â€œconversion up 37%â€

Git commit diff of winning variant auto-merged.

âš¡ Stretch Add-Ons (if you have time)

Feature Exploration Mode: agent invents new experiments (e.g. â€œtry onboarding flowâ€ or â€œadd free trial bannerâ€).

Reward Function Editing: instead of conversions, optimize any metric (load time, engagement, readability).

Human-in-the-loop: you can upvote / downvote experiments manually to steer evolution.

Dashboard for ongoing self-improvement: list of experiments, metrics, and live preview links.

ğŸ§  Key Narrative for the Hackathon Pitch

â€œInstead of a coding agent that writes features once, we built a self-improving system that continuously experiments, measures, and learns â€” turning your product into its own growth engineer.â€